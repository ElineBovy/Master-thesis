{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import cvxpy as cp\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "import scipy as sp\n",
    "from scipy import sparse\n",
    "from operator import itemgetter\n",
    "from itertools import groupby\n",
    "\n",
    "float_formatter = \"{:.6f}\".format\n",
    "np.set_printoptions(formatter={'float_kind':float_formatter})\n",
    "\n",
    "floor = lambda num, precision: ((num*10**precision)//1)/(10**precision)\n",
    "ceil = lambda num, precision: -((-num*10**precision)//1)/(10**precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(problem_name): #some changes needed if only one state, action or observation\n",
    "    global states_list, obs_list, act_list\n",
    "    global states, actions, obs\n",
    "    global obs_states_list, obs_act_list\n",
    "    global trns_matrices, initial_belief, reward\n",
    "\n",
    "    file_name = \"initial_data/\"+problem_name+\".txt\"\n",
    "\n",
    "    states_list = np.loadtxt(file_name, dtype = str, max_rows = 2)\n",
    "    obs_list = np.loadtxt(file_name, dtype = str, skiprows = 3, max_rows = 2)\n",
    "    act_list = np.loadtxt(file_name, dtype = str, skiprows = 6, max_rows = 2)\n",
    "\n",
    "    states = len(states_list)\n",
    "    actions = len(act_list)\n",
    "    obs = len(obs_list)\n",
    "\n",
    "    #unequal datatypes\n",
    "    obs_states_list = []\n",
    "    for i in range(obs):\n",
    "        temp = np.loadtxt(file_name, dtype = str, skiprows = 10+i, max_rows = 1)\n",
    "        obs_states_list.append((temp[0], [np.where(states_list == s)[0][0] for s in temp[1:]]))\n",
    "\n",
    "    obs_act_list = []\n",
    "    for i in range(obs):\n",
    "        temp = np.loadtxt(file_name, dtype = str, skiprows = 12+obs+i, max_rows = 1)\n",
    "        obs_act_list.append((temp[0], [np.where(act_list == s)[0][0] for s in temp[1:]]))\n",
    "\n",
    "    trns_data = np.loadtxt(file_name, dtype = float, skiprows = 14+2*obs, max_rows= actions*(states+2)).reshape((actions,states,states*2))\n",
    "    trns_matrices = []\n",
    "    for a in range(actions):\n",
    "        trns_matrices.append(sparse.csr_matrix(trns_data[a]))\n",
    "\n",
    "    initial_belief_data = np.loadtxt(file_name, dtype = float, skiprows= 14+2*obs+actions*(states+2), max_rows=2).reshape((states,2))\n",
    "    initial_belief_data[:,0] = -initial_belief_data[:,0]\n",
    "    initial_belief = (sparse.csr_matrix(initial_belief_data), [])\n",
    "\n",
    "    reward = np.transpose(np.loadtxt(file_name, dtype = float, skiprows= 14+2*obs+actions*(states+2)+3, max_rows=states).reshape(states,actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_sparse(problem_name):\n",
    "    global states_list, obs_list, act_list\n",
    "    global states, actions, obs\n",
    "    global obs_states_list, obs_act_list\n",
    "    global trns_matrices, initial_belief, reward\n",
    "\n",
    "    file_name = \"initial_data/\"+problem_name+\".txt\"\n",
    "\n",
    "    states_list = np.loadtxt(file_name, dtype = str, max_rows = 2)\n",
    "    obs_list = np.loadtxt(file_name, dtype = str, skiprows = 3, max_rows = 2)\n",
    "    act_list = np.loadtxt(file_name, dtype = str, skiprows = 6, max_rows = 2)\n",
    "\n",
    "    states = len(states_list)\n",
    "    actions = len(act_list)\n",
    "    obs = len(obs_list)\n",
    "\n",
    "    #unequal datatypes\n",
    "    obs_states_list = []\n",
    "    for i in range(obs):\n",
    "        temp = np.loadtxt(file_name, dtype = str, skiprows = 10+i, max_rows = 1)\n",
    "        obs_states_list.append((temp[0], [np.where(states_list == s)[0][0] for s in temp[1:]]))\n",
    "\n",
    "    obs_act_list = []\n",
    "    for i in range(obs):\n",
    "        temp = np.loadtxt(file_name, dtype = str, skiprows = 12+obs+i, max_rows = 1)\n",
    "        obs_act_list.append((temp[0], [np.where(act_list == s)[0][0] for s in temp[1:]]))\n",
    "\n",
    "    nr_initial_states = np.loadtxt(file_name, dtype = int, skiprows= 14+2*obs, max_rows=1)\n",
    "    initial_belief_data = np.loadtxt(file_name, dtype = str, skiprows= 15+2*obs, max_rows=nr_initial_states).reshape(1,3)\n",
    "    rows = [int(i[0][1:]) for i in initial_belief_data for j in range(2)]\n",
    "    cols = [j for i in range(nr_initial_states) for j in [0,1]]\n",
    "    data = [-float(initial_belief_data[i][j+1]) if j%2==0 else float(initial_belief_data[i][j+1]) for i in range(nr_initial_states) for j in range(2)]\n",
    "    initial_belief = (sparse.csr_matrix((data,(rows,cols)),shape = (states,2)), [])\n",
    "\n",
    "    nr_rewards = np.loadtxt(file_name, dtype = int, skiprows= 17+nr_initial_states+2*obs, max_rows=1)\n",
    "    reward_data = np.loadtxt(file_name, dtype = str, skiprows= 18+nr_initial_states+2*obs, max_rows=nr_rewards)\n",
    "    reward = np.zeros((states, actions))\n",
    "    for i in range(nr_rewards):\n",
    "        s = int(reward_data[i][0])\n",
    "        a = np.where(act_list == reward_data[i][1])[0][0]\n",
    "        reward[s,a] = reward_data[i][2]\n",
    "    reward = np.transpose(reward)\n",
    "    \n",
    "    nr_trns = np.loadtxt(file_name, dtype = int, skiprows= 19+nr_initial_states+nr_rewards+2*obs, max_rows=1)\n",
    "    trns_data =  np.loadtxt(file_name, dtype = str, skiprows = 21+nr_initial_states+nr_rewards+2*obs, max_rows= nr_trns)\n",
    "    trns_data = sorted(trns_data,key=itemgetter(1))\n",
    "    trns_data = [[k,list(g)] for k, g in (groupby(trns_data, key=itemgetter(1)))]\n",
    "    trns_matrices = []\n",
    "    for a in range(actions):\n",
    "        rows = [int(item[0]) for i in range(2) for item in trns_data[a][1]]\n",
    "        cols = [2*int(item[2])+i for i in range(2) for item in trns_data[a][1]]\n",
    "        data = [float(item[3+i]) for i in range(2) for item in trns_data[a][1]]\n",
    "        trns_matrices.append(sparse.csr_matrix((data,(rows,cols)),shape = (states,states*2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_constants():\n",
    "    global n,m\n",
    "    \n",
    "    n = states**2+states\n",
    "    m = 2*states**2 + 4*states + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precomputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precomp():\n",
    "    global c_vecs\n",
    "    global get_Am_n, get_c_vec_a_il_jl\n",
    "    global relevant_states_list\n",
    "\n",
    "    data, rows, cols = np.zeros(4*states), np.zeros(4*states), np.zeros(4*states)\n",
    "    for i in range(states):\n",
    "        rows[4*i:4*i+4] = i\n",
    "        cols[4*i:4*i+4] = [i, i+states, 2*states, 2*states+1]\n",
    "        data[4*i:4*i+4] = [-1,1,1,-1]\n",
    "    Am_small = sparse.csr_matrix((data,(rows,cols)),shape = (states,2*states+2))\n",
    "    get_Am_n = lambda n: Am_small[:n,[k*states+i for k in range(2) for i in range(n)]+[2*states, 2*states+1]]\n",
    "\n",
    "    relevant_states_list = [[[]]*states]*actions\n",
    "    c_vecs = [None] * actions\n",
    "    for a in range(actions):\n",
    "        data, rows, cols = [],[],[]\n",
    "        temp_list = [[]]*states\n",
    "        trns_rows, trns_cols = trns_matrices[a].nonzero()\n",
    "        rows += [i for i in trns_rows]\n",
    "        cols += [j/2 if j%2 == 0 else ((j-1)/2)+states for j in trns_cols]\n",
    "        data += [-trns_matrices[a][i,j] if j%2 == 0 else trns_matrices[a][i,j] for i, j in zip(trns_rows, trns_cols)]\n",
    "        for i in range(states):\n",
    "            if (trns_matrices[a][i].getnnz() > 0):\n",
    "                rows += [i, i]\n",
    "                cols += [2*states, 2*states+1]\n",
    "                data += [1, -1]\n",
    "                temp_list[i] = [int(j/2) for j in trns_matrices[a][i].nonzero()[1] if j%2==0]\n",
    "        relevant_states_list[a] = temp_list\n",
    "        c_vecs[a] = sparse.csr_matrix((data,(rows,cols)),shape = (states,2*states+2))\n",
    "    get_c_vec_a_il_jl = lambda a, il, jl: c_vecs[a][[i for i in il],:][:,[j+k*states for k in range(2) for j in jl]+[2*states, 2*states+1]]\n",
    "\n",
    "    for a in range(actions):\n",
    "        print(f\"Action: {act_list[a]}\")\n",
    "        for i in range(states):\n",
    "            suc_states = relevant_states_list[a][i]\n",
    "            nr_suc_states = len(suc_states)\n",
    "            \n",
    "            if(nr_suc_states > 0):\n",
    "                transition_model = gp.Model(\"Model over the uncertain transitions from one state\")\n",
    "                transition_model.params.LogToConsole = 0\n",
    "                transition_model.params.TimeLimit = 120\n",
    "\n",
    "                xs = transition_model.addMVar(shape = nr_suc_states, vtype = GRB.CONTINUOUS, name = \"xs\")\n",
    "                transition_model.addConstr(np.transpose(get_Am_n(nr_suc_states)) @ xs <= get_c_vec_a_il_jl(a,[i],suc_states), name = \"c\")\n",
    "\n",
    "                for j in range(nr_suc_states):\n",
    "                    obj_vec = np.zeros(nr_suc_states)\n",
    "                    obj_vec[j] = 1\n",
    "                    try:\n",
    "                        transition_model.setObjective(obj_vec @ xs, GRB.MINIMIZE)\n",
    "                        transition_model.optimize()\n",
    "                        if transition_model.status == GRB.OPTIMAL:\n",
    "                            min_data = -np.clip(round(transition_model.objVal, precision), 10**(-precision), 1)\n",
    "                            # min_data = -transition_model.objVal\n",
    "                            if min_data < c_vecs[a][i,suc_states[j]]:\n",
    "                                print(f\"Improved lower bound transition P({i},{act_list[a]},{suc_states[j]}): {-c_vecs[a][i,suc_states[j]]} -> {-min_data}\")\n",
    "                                c_vecs[a][i,suc_states[j]] = min_data\n",
    "                        else:\n",
    "                            print(f\"Not optimal min. State: {i}, State: {suc_states[j]}\")\n",
    "                    except gp.GurobiError as e:\n",
    "                        print(\"Error code \" + str(e.errno) + \": \" + str(e))\n",
    "                    except AttributeError:\n",
    "                        print(\"Encountered an attribute error\")\n",
    "\n",
    "                    try:\n",
    "                        transition_model.setObjective(obj_vec @ xs, GRB.MAXIMIZE)\n",
    "                        transition_model.optimize()\n",
    "                        if transition_model.status == GRB.OPTIMAL:\n",
    "                            max_data = np.clip(round(transition_model.objVal, precision), 10**(-precision), 1)\n",
    "                            # max_data = transition_model.objVal\n",
    "                            if max_data < c_vecs[a][i,states+suc_states[j]]:\n",
    "                                c_vecs[a][i,states+suc_states[j]] = max_data\n",
    "                                print(f\"Improved upper bound transition P({i},{act_list[a]},{suc_states[j]}): {c_vecs[a][i,states+suc_states[j]]} -> {max_data}\")\n",
    "                        else:\n",
    "                            print(f\"Not optimal max. State: {i}, State: {suc_states[j]}\")\n",
    "                    except gp.GurobiError as e:\n",
    "                        print(\"Error code \" + str(e.errno) + \": \" + str(e))\n",
    "                    except AttributeError:\n",
    "                        print(\"Encountered an attribute error\")\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precomp_min_max():\n",
    "    global maximums, minimums\n",
    "    \n",
    "    maximums, minimums = [None]*actions, [None]*actions\n",
    "\n",
    "    for a in range(actions):\n",
    "        min_data, max_data, rows, cols = [],[],[],[]\n",
    "        print(f\"Action: {act_list[a]}\")\n",
    "        for i in range(states):\n",
    "            suc_states = relevant_states_list[a][i]\n",
    "            nr_suc_states = len(suc_states)\n",
    "            \n",
    "            if(nr_suc_states > 0):\n",
    "                transition_model = gp.Model(\"Model over the uncertain transitions from one state\")\n",
    "                transition_model.params.LogToConsole = 0\n",
    "                transition_model.params.TimeLimit = 120\n",
    "\n",
    "                xs = transition_model.addMVar(shape = nr_suc_states, vtype = GRB.CONTINUOUS, name = \"xs\")\n",
    "                transition_model.addConstr(np.transpose(get_Am_n(nr_suc_states)) @ xs <= get_c_vec_a_il_jl(a,[i],suc_states), name = \"c\")\n",
    "                \n",
    "                for o in range(obs):\n",
    "                    obs_suc_states = (set(suc_states) & set(obs_states_list[o][1]))\n",
    "                    if len(obs_suc_states) > 0:\n",
    "                        obj_vec = np.array([int(s in obs_suc_states) for s in suc_states])\n",
    "                        rows += [o]\n",
    "                        cols += [i]\n",
    "                        try:\n",
    "                            transition_model.setObjective(obj_vec @ xs, GRB.MINIMIZE)\n",
    "                            transition_model.optimize()\n",
    "                            if transition_model.status == GRB.OPTIMAL:\n",
    "                                min_data += [np.clip(round(transition_model.objVal, precision), 10**(-precision), 1)]\n",
    "                            else:\n",
    "                                print(f\"Not optimal min. State: {i}, Rel states: {suc_states}\")\n",
    "                                min_data += [float('inf')]\n",
    "                        except gp.GurobiError as e:\n",
    "                            print(\"Error code \" + str(e.errno) + \": \" + str(e))\n",
    "                        except AttributeError:\n",
    "                            print(\"Encountered an attribute error\")\n",
    "\n",
    "                        try:\n",
    "                            transition_model.setObjective(obj_vec @ xs, GRB.MAXIMIZE)\n",
    "                            transition_model.optimize()\n",
    "                            if transition_model.status == GRB.OPTIMAL:\n",
    "                                max_data += [np.clip(round(transition_model.objVal, precision), 10**(-precision), 1)]\n",
    "                                # max_data += [transition_model.objVal]\n",
    "                            else:\n",
    "                                print(f\"Not optimal max. State: {i}, Rel states: {suc_states}\")\n",
    "                                max_data += [float('-inf')]\n",
    "                        except gp.GurobiError as e:\n",
    "                            print(\"Error code \" + str(e.errno) + \": \" + str(e))\n",
    "                        except AttributeError:\n",
    "                            print(\"Encountered an attribute error\")\n",
    "        minimums[a] = sparse.csr_matrix((min_data,(rows,cols)),shape = (obs,states))\n",
    "        maximums[a] = sparse.csr_matrix((max_data,(rows,cols)),shape = (obs,states))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precompute transition samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precomp_trns_samples(spud, factor):\n",
    "    global action_trns_samples\n",
    "    global get_trns_samples\n",
    "\n",
    "    # def generate_random_samples(c_vec, spud, precision):\n",
    "    # usefull states and constant states\n",
    "    action_trns_samples = [None]*actions\n",
    "    nr_trns_samples = np.ones((actions, states), int)\n",
    "    for a in range(actions):\n",
    "        print(f\"Action: {act_list[a]}\")\n",
    "        trns_samples = [None]*states\n",
    "        for i in range(states):\n",
    "            suc_states = relevant_states_list[a][i]\n",
    "            nr_suc_states = len(suc_states)\n",
    "\n",
    "            c_vec = get_c_vec_a_il_jl(a, [i], suc_states)\n",
    "            constant_states = [j for j in range(nr_suc_states) if (-c_vec[0,j] == c_vec[0,nr_suc_states+j])]\n",
    "            nz_nc_states = [j for j in range(nr_suc_states) if (-c_vec[0,j] != c_vec[0,nr_suc_states+j])]\n",
    "\n",
    "            c_rows, c_cols, c_data = [],[],[]\n",
    "            for j in constant_states:\n",
    "                c_rows += [0]\n",
    "                c_cols += [suc_states[j]]\n",
    "                c_data += [c_vec[0,nr_suc_states+j]]\n",
    "            nr_nz_nc_states = len(nz_nc_states)\n",
    "            if nr_nz_nc_states == 0:\n",
    "                trns_samples[i] = sparse.csr_matrix((c_data,(c_rows,c_cols)),shape = (1,states))\n",
    "            elif nr_nz_nc_states == 1:\n",
    "                j = nz_nc_states[0]\n",
    "                temp = 1 - sum(c_data)\n",
    "                if -c_vec[0,j] <= temp and temp <= c_vec[0,nr_suc_states+j]:\n",
    "                    c_rows += [0]\n",
    "                    c_cols += [suc_states[j]]\n",
    "                    c_data += temp\n",
    "                    trns_samples[i] = sparse.csr_matrix((c_data,(c_rows,c_cols)),shape = (1,states))\n",
    "                else:\n",
    "                    print(f\"BIG ERROR, TRANSITIONS FROM STATE {i} INFEASIBLE\")\n",
    "            else:\n",
    "                nr_samples = round(sum(round(c_vec[0,nr_suc_states+nz_nc_states[j]] + c_vec[0,nz_nc_states[j]],precision) for j in range(nr_nz_nc_states))*spud)\n",
    "                nr_samples = max(nr_samples, 1)\n",
    "                nr_trns_samples[a][i] = int(np.copy(nr_samples))\n",
    "                nr_samples = factor*nr_samples\n",
    "\n",
    "                nz_nc_rows, nz_nc_cols, nz_nc_data = [],[],[]\n",
    "                for sample in range(nr_samples):\n",
    "                    while True:\n",
    "                        rows, cols, data = [],[],[]\n",
    "                        \n",
    "                        for j in range(nr_nz_nc_states-1):\n",
    "                            k = nz_nc_states[j]\n",
    "                            rows += [sample]\n",
    "                            cols += [suc_states[k]]\n",
    "                            data += [np.random.uniform(-c_vec[0,k], c_vec[0,nr_suc_states+k])]\n",
    "                    \n",
    "                        k = nz_nc_states[-1]\n",
    "                        temp = 1 - (sum(c_data)+sum(data))\n",
    "                        if -c_vec[0,k] <= temp and temp <= c_vec[0,nr_suc_states+k]:\n",
    "                            nz_nc_rows += [sample]*len(constant_states) + rows + [sample]\n",
    "                            nz_nc_cols += c_cols + cols + [suc_states[k]]\n",
    "                            nz_nc_data += c_data + data + [temp]\n",
    "                            break\n",
    "                trns_samples[i] = sparse.csr_matrix((nz_nc_data,(nz_nc_rows,nz_nc_cols)),shape = (nr_samples,states))\n",
    "                \n",
    "        action_trns_samples[a] = trns_samples\n",
    "\n",
    "    get_trns_samples = lambda a, il: [action_trns_samples[a][i][np.random.randint(0,action_trns_samples[a][i].shape[0])] for i in il]\n",
    "\n",
    "    return nr_trns_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update belief constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_belief_constraints(belief, nzb_states):\n",
    "    global belief_model, ys, t\n",
    "    global bui_cons, bdc_cons, bdc_A, c_bui_bpd\n",
    "    \n",
    "    belief_model = None\n",
    "    nr_nzb_states = len(nzb_states)\n",
    "    if nr_nzb_states == 0:\n",
    "        print(\"BIG ERROR, ALL ZERO BELIEF STATE\")\n",
    "    else:\n",
    "        bui = np.transpose(belief[0])\n",
    "        bdc = belief[1]\n",
    "\n",
    "        belief_model = gp.Model(\"Model over an old uncertain belief state\")\n",
    "        belief_model.params.LogToConsole = 0\n",
    "        belief_model.params.TimeLimit = 120\n",
    "\n",
    "        ys = belief_model.addMVar(shape = nr_nzb_states, vtype = GRB.CONTINUOUS, name = \"ys\")\n",
    "        t = belief_model.addMVar(shape =1, vtype = GRB.CONTINUOUS, name = \"t\")\n",
    "        t.lb = 1\n",
    "        t.ub = 1\n",
    "\n",
    "        bui_cons = np.array(list(bui[bui.nonzero()].A1)+[1,-1])\n",
    "        try:\n",
    "            c_bui_bpd = belief_model.addConstr(np.transpose(get_Am_n(nr_nzb_states)) @ ys <= bui_cons*t, name = \"c_bui_bpd\")\n",
    "        except:\n",
    "            print(\"Error\")\n",
    "\n",
    "        if len(bdc) > 0:\n",
    "            rows, cols, data = [],[],[]\n",
    "            for i in range(len(bdc)):\n",
    "                # need the intersection with nzb_states\n",
    "                bdc_nzb_indices = [j for j in range(nr_nzb_states) if (nzb_states[j] in bdc[i][0])]\n",
    "                nzb_bdc_indices = [j for j in range(len(bdc[i][0])) if (bdc[i][0][j] in nzb_states)]\n",
    "                rows += [i]*len(bdc_nzb_indices)\n",
    "                cols += bdc_nzb_indices\n",
    "                data += [bdc[i][1][j] for j in nzb_bdc_indices]\n",
    "            bdc_A = sparse.csr_matrix((data,(rows,cols)),shape = (len(bdc), nr_nzb_states))\n",
    "            bdc_cons = np.array([i[2] for i in bdc])\n",
    "            c_bdc = belief_model.addConstr(bdc_A @ ys <= bdc_cons*t, name = \"c_bdc\")\n",
    "        belief_model.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transition computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_transition(action, observation, nzb_states, precision):\n",
    "    global belief_model\n",
    "    \n",
    "    min_trns = float('inf')\n",
    "    max_trns = float('-inf')\n",
    "    \n",
    "    try:\n",
    "        belief_model.setObjective(minimums[action][observation,nzb_states]@ys, GRB.MINIMIZE)\n",
    "        belief_model.optimize()\n",
    "        if belief_model.status == GRB.OPTIMAL:\n",
    "            min_trns = round(belief_model.objVal,precision)\n",
    "        else:\n",
    "            print(\"Not optimal min comp_transition\")\n",
    "    except gp.GurobiError as e:\n",
    "        print(\"Error code \" + str(e.errno) + \": \" + str(e))\n",
    "    except AttributeError:\n",
    "        print(\"Encountered an attribute error\")\n",
    "        \n",
    "    try:\n",
    "        belief_model.setObjective(maximums[action][observation,nzb_states]@ys, GRB.MAXIMIZE)\n",
    "        belief_model.optimize()\n",
    "        if belief_model.status == GRB.OPTIMAL:\n",
    "            max_trns = round(belief_model.objVal,precision)\n",
    "        else:\n",
    "            print(\"Not optimal max comp_transition\")\n",
    "    except gp.GurobiError as e:\n",
    "        print(\"Error code \" + str(e.errno) + \": \" + str(e))\n",
    "    except AttributeError:\n",
    "        print(\"Encountered an attribute error\")\n",
    "\n",
    "    return [np.clip(min_trns, 10**(-precision), 1), np.clip(max_trns, 10**(-precision), 1)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reward computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_reward(action, nzb_states, precision):\n",
    "    global belief_model\n",
    "    a_reward = reward[action][nzb_states]\n",
    "    \n",
    "    min_reward = float('inf')\n",
    "    max_reward = float('-inf')\n",
    "\n",
    "    try:\n",
    "        belief_model.setObjective(a_reward@ys, GRB.MINIMIZE)\n",
    "        belief_model.optimize()\n",
    "        if belief_model.status == GRB.OPTIMAL:\n",
    "            min_reward = round(belief_model.objVal,precision)\n",
    "        else:\n",
    "            print(\"Not optimal min comp_reward\")\n",
    "    except gp.GurobiError as e:\n",
    "        print(\"Error code \" + str(e.errno) + \": \" + str(e))\n",
    "    except AttributeError:\n",
    "        print(\"Encountered an attribute error\")\n",
    "        \n",
    "    try:\n",
    "        belief_model.setObjective(a_reward@ys, GRB.MAXIMIZE)\n",
    "        belief_model.optimize()\n",
    "        if belief_model.status == GRB.OPTIMAL:\n",
    "            max_reward = round(belief_model.objVal,precision)\n",
    "        else:\n",
    "            print(\"Not optimal max comp_reward\")\n",
    "    except gp.GurobiError as e:\n",
    "        print(\"Error code \" + str(e.errno) + \": \" + str(e))\n",
    "    except AttributeError:\n",
    "        print(\"Encountered an attribute error\")\n",
    "\n",
    "    return [min_reward, max_reward]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate random samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_belief_samples(nzb_states, nr_samples, precision):\n",
    "    nr_nzb_states = len(nzb_states)\n",
    "\n",
    "    constant_states = [j for j in range(nr_nzb_states) if (-bui_cons[j] == bui_cons[nr_nzb_states+j])]\n",
    "    nz_nc_states = [j for j in range(nr_nzb_states) if (-bui_cons[j] != bui_cons[nr_nzb_states+j])]\n",
    "    \n",
    "    c_rows, c_cols, c_data = [],[],[]\n",
    "    for j in constant_states:\n",
    "        c_rows += [0]\n",
    "        c_cols += [nzb_states[j]]\n",
    "        c_data += [bui_cons[nr_nzb_states+j]]\n",
    "    \n",
    "    nr_nz_nc_states = len(nz_nc_states)\n",
    "    if nr_nz_nc_states == 0:\n",
    "        return sparse.csr_matrix((c_data,(c_rows,c_cols)),shape = (1,states)), 0\n",
    "    elif nr_nz_nc_states == 1:\n",
    "        j = nz_nc_states[0]\n",
    "        temp = 1 - sum(c_data)\n",
    "        if -bui_cons[j] <= temp and temp <= bui_cons[nr_nzb_states+j]:\n",
    "            c_rows += [0]\n",
    "            c_cols += [nzb_states[j]]\n",
    "            c_data += [temp]\n",
    "            return sparse.csr_matrix((c_data,(c_rows,c_cols)),shape = (1,states)), 0\n",
    "        else:\n",
    "            print(f\"BIG ERROR, CURRENT UNCERTAIN BELIEF STATE INFEASIBLE\")\n",
    "    else:\n",
    "        nz_nc_rows, nz_nc_cols, nz_nc_data = [],[],[]\n",
    "        for sample in range(nr_samples):\n",
    "            while True:\n",
    "                rows, cols, data = [],[],[]\n",
    "                \n",
    "                for j in range(nr_nz_nc_states-1):\n",
    "                    k = nz_nc_states[j]\n",
    "                    rows += [sample]\n",
    "                    cols += [nzb_states[k]]\n",
    "                    data += [np.random.uniform(-bui_cons[k], bui_cons[nr_nzb_states+k])]\n",
    "            \n",
    "                k = nz_nc_states[-1]\n",
    "                temp = 1 - (sum(c_data)+sum(data))\n",
    "                if -bui_cons[k] <= temp and temp <= bui_cons[nr_nzb_states+k]:\n",
    "                    check_vec = np.transpose(sparse.csr_matrix((c_data+data+[temp],(np.zeros(nr_nzb_states),constant_states+nz_nc_states)),shape = (1,nr_nzb_states)))\n",
    "                    if (bdc_A @ check_vec <= bdc_cons).all:\n",
    "                        nz_nc_rows += [sample]*len(constant_states) + rows + [sample]\n",
    "                        nz_nc_cols += c_cols + cols + [nzb_states[k]]\n",
    "                        nz_nc_data += c_data + data + [temp]\n",
    "                        break\n",
    "        print(\"- - - - - - - - - - Belief samples generated - - - - - - - - - -\")\n",
    "        return sparse.csr_matrix((nz_nc_data,(nz_nc_rows,nz_nc_cols)),shape = (nr_samples,states)), nr_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Belief update computation (sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling_bui(j, nzb_states, rel_obs_suc_states, trns_samples, belief_sample):\n",
    "    return sum([belief_sample[0,nzb_states[i]] * trns_samples[i][0,j] for i in range(len(nzb_states))])/sum([belief_sample[0,nzb_states[i]] * sum([trns_samples[i][0,k] for k in rel_obs_suc_states]) for i in range(len(nzb_states))])\n",
    "\n",
    "def sampling_bc(l, j, nzb_states, trns_samples, belief_sample):\n",
    "    return (belief_sample[0,nzb_states[l]] * trns_samples[l][0,j])/sum([belief_sample[0,nzb_states[i]] * trns_samples[i][0,j] for i in range(len(nzb_states))])\n",
    "\n",
    "def sampling_n(l, nzb_states, rel_obs_suc_states, trns_samples, belief_sample):\n",
    "    return (belief_sample[0,nzb_states[l]] * sum([trns_samples[l][0,k] for k in rel_obs_suc_states]))/sum([belief_sample[0,nzb_states[i]] * sum([trns_samples[i][0,k] for k in rel_obs_suc_states]) for i in range(len(nzb_states))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_belief_update_sampling(a, o, nzb_states, rel_obs_suc_states, spud, nr_trns_samples, precision, belief):\n",
    "    new_bui = None\n",
    "    new_bdc = []\n",
    "    tries = 0\n",
    "\n",
    "    if len(rel_obs_suc_states) == 1:\n",
    "        cs = rel_obs_suc_states[0]\n",
    "        new_bui = sparse.csr_matrix(([-1.0,1.0],([cs,cs],[0,1])), shape = (states,2))\n",
    "    else:\n",
    "        while True:\n",
    "            nr_nzb_states = len(nzb_states)\n",
    "            \n",
    "            nr_bel_samples = max(round(sum(round(bui_cons[nr_nzb_states+j] + bui_cons[j],precision) for j in range(nr_nzb_states))*spud),1)\n",
    "            nr_samples = max(max(nr_trns_samples[a][nzb_states]), nr_bel_samples)\n",
    "\n",
    "            bel_samples, nr_bel_samples = generate_belief_samples(nzb_states, nr_samples, precision)\n",
    "            trns_samples = [get_trns_samples(a,nzb_states) for r in range(nr_samples)]\n",
    "\n",
    "            # Belief uncertainty intervals\n",
    "            nr_ros_states = len(rel_obs_suc_states)\n",
    "            cols = np.zeros(2*nr_ros_states, dtype = int)\n",
    "            cols[range(1,2*nr_ros_states, 2)] = 1\n",
    "            rows, data = np.zeros(2*nr_ros_states), np.zeros(2 * nr_ros_states)\n",
    "            for k in range(nr_ros_states): #rel_obs_suc_states\n",
    "                j = rel_obs_suc_states[k]\n",
    "                bui_results = [sampling_bui(j, nzb_states, rel_obs_suc_states, trns_samples[r], bel_samples[min(r,nr_bel_samples)]) for r in range(nr_samples)]\n",
    "                rows[2*k], rows[2*k+1] = j, j\n",
    "                data[2*k] = -np.clip(round(min(bui_results),precision), 10**(-precision), 1)\n",
    "                data[2*k+1] = np.clip(round(max(bui_results),precision), 10**(-precision), 1)\n",
    "            new_bui = sparse.csr_matrix((data,(rows,cols)), shape = (states,2))\n",
    "\n",
    "            # Belief distribution constraints\n",
    "            for k in range(nr_nzb_states):\n",
    "                i = nzb_states[k]\n",
    "                i_suc_states = sorted(set(relevant_states_list[a][i]) & set(obs_states_list[o][1]))\n",
    "\n",
    "                if len(i_suc_states) > 0:\n",
    "                    min_coeffs, max_coeffs = [None] * len(i_suc_states), [None] * len(i_suc_states)\n",
    "                    for l in range(len(i_suc_states)):\n",
    "                        j = i_suc_states[l]\n",
    "                        bc_results = [sampling_bc(k, j, nzb_states, trns_samples[r], bel_samples[min(r,nr_bel_samples)]) for r in range(nr_samples)]\n",
    "                        min_coeffs[l] = np.clip(round(min(bc_results),precision), 10**(-precision), 1)\n",
    "                        max_coeffs[l] = -np.clip(round(max(bc_results),precision),  10**(-precision), 1)\n",
    "\n",
    "                    n_results = [sampling_n(k, nzb_states, rel_obs_suc_states, trns_samples[r], bel_samples[min(r,nr_bel_samples)]) for r in range(nr_samples)]\n",
    "                    min_const = -np.clip(round(min(n_results),precision), 10**(-precision), 1)\n",
    "                    max_const = np.clip(round(max(n_results),precision), 10**(-precision), 1)\n",
    "\n",
    "                    new_bdc.append((i_suc_states,max_coeffs,min_const))\n",
    "                    new_bdc.append((i_suc_states,min_coeffs,max_const))\n",
    "            \n",
    "            update_belief_constraints((new_bui, new_bdc), rel_obs_suc_states)\n",
    "            belief_model.setObjective(0, GRB.MINIMIZE)\n",
    "            belief_model.optimize()\n",
    "            if belief_model.status != GRB.INFEASIBLE:\n",
    "                update_belief_constraints(belief, nzb_states)\n",
    "                break\n",
    "            elif tries >= 10:\n",
    "                raise RuntimeError(\"Not able to compute a feasible new belief state\")\n",
    "            else:\n",
    "                tries += 1\n",
    "    return (new_bui, new_bdc)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Belief update computation (partial decoupling, Gurobi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoupling_g_bui(a, o, j, nzb_states, precision):\n",
    "    global belief_model\n",
    "    nr_nzb_states = len(nzb_states)\n",
    "\n",
    "    min_bui = float('inf')\n",
    "    max_bui = float('-inf')\n",
    "    \n",
    "    num = lambda ys: sum([ys[l]*-c_vecs[a][nzb_states[l],j] for l in range(nr_nzb_states)])\n",
    "    denom = lambda ys: sum([ys[l]*maximums[a][o,nzb_states[l]] for l in range(nr_nzb_states)])\n",
    "    \n",
    "    z = belief_model.addVar(vtype = GRB.CONTINUOUS, name = \"z\")\n",
    "    zc = belief_model.addConstr(z*denom(ys) == num(ys))\n",
    "    try:\n",
    "        belief_model.setObjective(z, GRB.MINIMIZE)\n",
    "        belief_model.optimize()\n",
    "        if belief_model.status == GRB.OPTIMAL:\n",
    "            min_bui = round(belief_model.objVal,precision)\n",
    "        else:\n",
    "            print(\"Not optimal min\")\n",
    "    except gp.GurobiError as e:\n",
    "        print(\"Error code \" + str(e.errno) + \": \" + str(e))\n",
    "    except AttributeError:\n",
    "        print(\"Encountered an attribute error\")\n",
    "\n",
    "    num = lambda ys: sum([ys[l]*c_vecs[a][nzb_states[l],states+j] for l in range(nr_nzb_states)])\n",
    "    denom = lambda ys: sum([ys[l]*minimums[a][o,nzb_states[l]] for l in range(nr_nzb_states)])\n",
    "    \n",
    "    belief_model.remove(zc)\n",
    "    zc = belief_model.addConstr(z*denom(ys) == num(ys))\n",
    "    try:\n",
    "        belief_model.setObjective(z, GRB.MAXIMIZE)\n",
    "        belief_model.optimize()\n",
    "        if belief_model.status == GRB.OPTIMAL:\n",
    "            max_bui = round(belief_model.objVal,precision)\n",
    "        else:\n",
    "            print(\"Not optimal max\")\n",
    "    except gp.GurobiError as e:\n",
    "        print(\"Error code \" + str(e.errno) + \": \" + str(e))\n",
    "    except AttributeError:\n",
    "        print(\"Encountered an attribute error\")\n",
    "\n",
    "    belief_model.remove(zc)\n",
    "    belief_model.remove(z)\n",
    "\n",
    "    return -np.clip(min_bui, 10**(-precision), 1), np.clip(max_bui, 10**(-precision), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoupling_g_bc(a, o, k, j, nzb_states, precision):\n",
    "    global belief_model\n",
    "    nr_nzb_states = len(nzb_states)\n",
    "    i = nzb_states[k]\n",
    "\n",
    "    min_bc = float('inf')\n",
    "    max_bc = float('-inf')\n",
    "    \n",
    "    num = lambda ys: ys[k]*-c_vecs[a][i,j]\n",
    "    denom = lambda ys: sum([ys[l]*c_vecs[a][nzb_states[l],states+j] for l in range(nr_nzb_states)])\n",
    "    \n",
    "    z = belief_model.addVar(vtype = GRB.CONTINUOUS, name = \"z\")\n",
    "    zc = belief_model.addConstr(z*denom(ys) == num(ys))\n",
    "    try:\n",
    "        belief_model.setObjective(z, GRB.MINIMIZE)\n",
    "        belief_model.optimize()\n",
    "        if belief_model.status == GRB.OPTIMAL:\n",
    "            min_bc = round(belief_model.objVal,precision)\n",
    "        else:\n",
    "            print(\"Not optimal min\")\n",
    "    except gp.GurobiError as e:\n",
    "        print(\"Error code \" + str(e.errno) + \": \" + str(e))\n",
    "    except AttributeError:\n",
    "        print(\"Encountered an attribute error\")\n",
    "\n",
    "    num = lambda ys: ys[k]*c_vecs[a][i,states+j]\n",
    "    denom = lambda ys: sum([ys[l]*-c_vecs[a][nzb_states[l],j] for l in range(nr_nzb_states)])\n",
    "    \n",
    "    belief_model.remove(zc)\n",
    "    zc = belief_model.addConstr(z*denom(ys) == num(ys))\n",
    "    try:\n",
    "        belief_model.setObjective(z, GRB.MAXIMIZE)\n",
    "        belief_model.optimize()\n",
    "        if belief_model.status == GRB.OPTIMAL:\n",
    "            max_bc = round(belief_model.objVal,precision)\n",
    "        else:\n",
    "            print(\"Not optimal max\")\n",
    "    except gp.GurobiError as e:\n",
    "        print(\"Error code \" + str(e.errno) + \": \" + str(e))\n",
    "    except AttributeError:\n",
    "        print(\"Encountered an attribute error\")\n",
    "    \n",
    "    belief_model.remove(zc)\n",
    "    belief_model.remove(z)\n",
    "    \n",
    "    return np.clip(min_bc, 10**(-precision), 1), -np.clip(max_bc, 10**(-precision), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoupling_g_n(a, o, k, nzb_states, precision):\n",
    "    global belief_model\n",
    "    nr_nzb_states = len(nzb_states)\n",
    "    i = nzb_states[k]\n",
    "\n",
    "    min_n = float('inf')\n",
    "    max_n = float('-inf')\n",
    "    \n",
    "    num = lambda ys: ys[k]*minimums[a][o,i]\n",
    "    denom = lambda ys: sum([ys[l]*maximums[a][o,nzb_states[l]] for l in range(nr_nzb_states)])\n",
    "    \n",
    "    z = belief_model.addVar(vtype = GRB.CONTINUOUS, name = \"z\")\n",
    "    zc = belief_model.addConstr(z*denom(ys) == num(ys))\n",
    "    try:\n",
    "        belief_model.setObjective(z, GRB.MINIMIZE)\n",
    "        belief_model.optimize()\n",
    "        if belief_model.status == GRB.OPTIMAL:\n",
    "            min_n = round(belief_model.objVal,precision)\n",
    "        else:\n",
    "            print(\"Not optimal min\")\n",
    "    except gp.GurobiError as e:\n",
    "        print(\"Error code \" + str(e.errno) + \": \" + str(e))\n",
    "    except AttributeError:\n",
    "        print(\"Encountered an attribute error\")\n",
    "\n",
    "    num = lambda ys: ys[k]*maximums[a][o,i]\n",
    "    denom = lambda ys: sum([ys[l]*minimums[a][o,nzb_states[l]] for l in range(nr_nzb_states)])\n",
    "    \n",
    "    belief_model.remove(zc)\n",
    "    zc = belief_model.addConstr(z*denom(ys) == num(ys))\n",
    "    try:\n",
    "        belief_model.setObjective(z, GRB.MAXIMIZE)\n",
    "        belief_model.optimize()\n",
    "        if belief_model.status == GRB.OPTIMAL:\n",
    "            max_n = round(belief_model.objVal,precision)\n",
    "        else:\n",
    "            print(\"Not optimal max\")\n",
    "    except gp.GurobiError as e:\n",
    "        print(\"Error code \" + str(e.errno) + \": \" + str(e))\n",
    "    except AttributeError:\n",
    "        print(\"Encountered an attribute error\")\n",
    "\n",
    "    belief_model.remove(zc)\n",
    "    belief_model.remove(z)\n",
    "    \n",
    "    return -np.clip(min_n, 10**(-precision), 1), np.clip(max_n, 10**(-precision), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_belief_update_decoupling_gurobi(a, o, nzb_states, rel_suc_states, rel_obs_suc_states, precision):\n",
    "    global belief_model\n",
    "    new_bui = None\n",
    "    new_bdc = []\n",
    "    \n",
    "    if len(rel_obs_suc_states) == 1:\n",
    "        cs = rel_obs_suc_states[0]\n",
    "        new_bui = sparse.csr_matrix(([-1.0,1.0],([cs,cs],[0,1])), shape = (states,2))\n",
    "    else:\n",
    "        belief_model.params.NonConvex = 2\n",
    "\n",
    "        nr_nzb_states = len(nzb_states)\n",
    "        \n",
    "        # Belief uncertainty intervals\n",
    "        nr_ros_states = len(rel_obs_suc_states)\n",
    "        cols = np.zeros(2*nr_ros_states, dtype = int)\n",
    "        cols[range(1,2*nr_ros_states, 2)] = 1\n",
    "        rows, data = np.zeros(2*nr_ros_states), np.zeros(2 * nr_ros_states)\n",
    "        for k in range(nr_ros_states): #rel_obs_suc_states\n",
    "            j = rel_obs_suc_states[k]\n",
    "            rows[2*k], rows[2*k+1] = j, j\n",
    "            data[2*k], data[2*k+1] = decoupling_g_bui(a, o, j, nzb_states, precision)\n",
    "        new_bui = sparse.csr_matrix((data,(rows,cols)), shape = (states,2))\n",
    "\n",
    "        # Belief distribution constraints\n",
    "        mbs_states = []\n",
    "        for i in rel_obs_suc_states:\n",
    "            if rel_suc_states.count(i) > 1:\n",
    "                mbs_states += [i]\n",
    "        for k in range(nr_nzb_states):\n",
    "            i = nzb_states[k]\n",
    "            i_suc_states = sorted(set(relevant_states_list[a][i]) & set(obs_states_list[o][1]))\n",
    "            \n",
    "            if len(i_suc_states) > 0:\n",
    "                min_coeffs, max_coeffs = [1] * len(i_suc_states), [-1] * len(i_suc_states)\n",
    "                for l in range(len(i_suc_states)):\n",
    "                    j = i_suc_states[l]\n",
    "                    if j in mbs_states:\n",
    "                        min_coeffs[l], max_coeffs[l] = decoupling_g_bc(a, o, k, j, nzb_states, precision)\n",
    "\n",
    "                min_const, max_const = decoupling_g_n(a, o, k, nzb_states, precision)\n",
    "\n",
    "                new_bdc.append((i_suc_states,max_coeffs,min_const))\n",
    "                new_bdc.append((i_suc_states,min_coeffs,max_const))\n",
    "        \n",
    "        belief_model.params.NonConvex = -1\n",
    "            \n",
    "    return (new_bui, new_bdc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Belief update computation (partial decoupling, Charnes-Cooper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoupling_cc_bui(a, o, j, nzb_states, precision):\n",
    "    global belief_model, t\n",
    "    nr_nzb_states = len(nzb_states)\n",
    "    \n",
    "    min_bui = float('inf')\n",
    "    max_bui = float('-inf')\n",
    "    \n",
    "    num = lambda ys: sum([ys[l]*-c_vecs[a][nzb_states[l],j] for l in range(nr_nzb_states)])\n",
    "    denom = lambda ys: sum([ys[l]*maximums[a][o,nzb_states[l]] for l in range(nr_nzb_states)])\n",
    "\n",
    "    zc = belief_model.addConstr(denom(ys) == 1)\n",
    "    t.lb = 0\n",
    "    t.ub = float('inf')\n",
    "\n",
    "    try:\n",
    "        belief_model.setObjective(num(ys), GRB.MINIMIZE)\n",
    "        belief_model.optimize()\n",
    "        if belief_model.status == GRB.OPTIMAL:\n",
    "            opt_vars = belief_model.getAttr(\"X\", belief_model.getVars())\n",
    "            min_bui = round(num(opt_vars)/denom(opt_vars),precision)\n",
    "        else:\n",
    "            print(f\"Not optimal min bui. a: {act_list[a]}, o: {obs_list[o]}, j: {states_list[j]}\")\n",
    "    except gp.GurobiError as e:\n",
    "        print(\"Error code \" + str(e.errno) + \": \" + str(e))\n",
    "    except AttributeError:\n",
    "        print(\"Encountered an attribute error\")\n",
    "    \n",
    "    num = lambda ys: sum([ys[l]*c_vecs[a][nzb_states[l],states+j] for l in range(nr_nzb_states)])\n",
    "    denom = lambda ys: sum([ys[l]*minimums[a][o,nzb_states[l]] for l in range(nr_nzb_states)])\n",
    "    \n",
    "    belief_model.remove(zc)\n",
    "    zc = belief_model.addConstr(denom(ys) == 1)\n",
    "    try:\n",
    "        belief_model.setObjective(num(ys), GRB.MAXIMIZE)\n",
    "        belief_model.optimize()\n",
    "        if belief_model.status == GRB.OPTIMAL:\n",
    "            opt_vars = belief_model.getAttr(\"X\", belief_model.getVars())\n",
    "            max_bui = round(num(opt_vars)/denom(opt_vars),precision)\n",
    "        else:\n",
    "            print(\"Not optimal max bui\")\n",
    "    except gp.GurobiError as e:\n",
    "        print(\"Error code \" + str(e.errno) + \": \" + str(e))\n",
    "    except AttributeError:\n",
    "        print(\"Encountered an attribute error\")\n",
    "    \n",
    "    belief_model.remove(zc)\n",
    "    t.lb = 1\n",
    "    t.ub = 1\n",
    "    \n",
    "    return -np.clip(min_bui, 10**(-precision), 1), np.clip(max_bui, 10**(-precision), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoupling_cc_bc(a, o, k, j, nzb_states, precision):\n",
    "    global belief_model\n",
    "    nr_nzb_states = len(nzb_states)\n",
    "    i = nzb_states[k]\n",
    "    \n",
    "    min_bc = float('inf')\n",
    "    max_bc = float('-inf')\n",
    "    \n",
    "    num = lambda ys: ys[k]*-c_vecs[a][i,j]\n",
    "    denom = lambda ys: sum([ys[l]*c_vecs[a][nzb_states[l],states+j] for l in range(nr_nzb_states)])\n",
    "    \n",
    "    zc = belief_model.addConstr(denom(ys) == 1)\n",
    "    t.lb = 0\n",
    "    t.ub = float('inf')\n",
    "    \n",
    "    try:\n",
    "        belief_model.setObjective(num(ys), GRB.MINIMIZE)\n",
    "        belief_model.optimize()\n",
    "        if belief_model.status == GRB.OPTIMAL:\n",
    "            opt_vars = belief_model.getAttr(\"X\", belief_model.getVars())\n",
    "            min_bc = round(num(opt_vars)/denom(opt_vars),precision)\n",
    "        else:\n",
    "            print(\"Not optimal min bc\")\n",
    "    except gp.GurobiError as e:\n",
    "        print(\"Error code \" + str(e.errno) + \": \" + str(e))\n",
    "    except AttributeError:\n",
    "        print(\"Encountered an attribute error\")\n",
    "\n",
    "    num = lambda ys: ys[k]*c_vecs[a][i,states+j]\n",
    "    denom = lambda ys: sum([ys[l]*-c_vecs[a][nzb_states[l],j] for l in range(nr_nzb_states)])\n",
    "    \n",
    "    belief_model.remove(zc)\n",
    "    zc = belief_model.addConstr(denom(ys) == 1)\n",
    "    try:\n",
    "        belief_model.setObjective(num(ys), GRB.MAXIMIZE)\n",
    "        belief_model.optimize()\n",
    "        if belief_model.status == GRB.OPTIMAL:\n",
    "            opt_vars = belief_model.getAttr(\"X\", belief_model.getVars())\n",
    "            max_bc = round(num(opt_vars)/denom(opt_vars),precision)\n",
    "        else:\n",
    "            print(\"Not optimal max bc\")\n",
    "    except gp.GurobiError as e:\n",
    "        print(\"Error code \" + str(e.errno) + \": \" + str(e))\n",
    "    except AttributeError:\n",
    "        print(\"Encountered an attribute error\")\n",
    "    \n",
    "    belief_model.remove(zc)\n",
    "    t.lb = 1\n",
    "    t.ub = 1\n",
    "    \n",
    "    return np.clip(min_bc, 10**(-precision), 1), -np.clip(max_bc, 10**(-precision), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoupling_cc_n(a, o, k, nzb_states, precision):\n",
    "    global belief_model\n",
    "    nr_nzb_states = len(nzb_states)\n",
    "    i = nzb_states[k]\n",
    "\n",
    "    min_n = float('inf')\n",
    "    max_n = float('-inf')\n",
    "    \n",
    "    num = lambda ys: ys[k]*minimums[a][o,i]\n",
    "    denom = lambda ys: sum([ys[l]*maximums[a][o,nzb_states[l]] for l in range(nr_nzb_states)])\n",
    "    \n",
    "    zc = belief_model.addConstr(denom(ys) == 1)\n",
    "    t.lb = 0\n",
    "    t.ub = float('inf')\n",
    "    \n",
    "    try:\n",
    "        belief_model.setObjective(num(ys), GRB.MINIMIZE)\n",
    "        belief_model.optimize()\n",
    "        if belief_model.status == GRB.OPTIMAL:\n",
    "            opt_vars = belief_model.getAttr(\"X\", belief_model.getVars())\n",
    "            min_n = round(num(opt_vars)/denom(opt_vars),precision)\n",
    "        else:\n",
    "            print(\"Not optimal min n\")\n",
    "    except gp.GurobiError as e:\n",
    "        print(\"Error code \" + str(e.errno) + \": \" + str(e))\n",
    "    except AttributeError:\n",
    "        print(\"Encountered an attribute error\")\n",
    "\n",
    "    num = lambda ys: ys[k]*maximums[a][o,i]\n",
    "    denom = lambda ys: sum([ys[l]*minimums[a][o,nzb_states[l]] for l in range(nr_nzb_states)])\n",
    "    \n",
    "    belief_model.remove(zc)\n",
    "    zc = belief_model.addConstr(denom(ys) == 1)\n",
    "    try:\n",
    "        belief_model.setObjective(num(ys), GRB.MAXIMIZE)\n",
    "        belief_model.optimize()\n",
    "        if belief_model.status == GRB.OPTIMAL:\n",
    "            opt_vars = belief_model.getAttr(\"X\", belief_model.getVars())\n",
    "            max_n = round(num(opt_vars)/denom(opt_vars),precision)\n",
    "        else:\n",
    "            print(\"Not optimal max n\")\n",
    "    except gp.GurobiError as e:\n",
    "        print(\"Error code \" + str(e.errno) + \": \" + str(e))\n",
    "    except AttributeError:\n",
    "        print(\"Encountered an attribute error\")\n",
    "\n",
    "    belief_model.remove(zc)\n",
    "    t.lb = 1\n",
    "    t.ub = 1\n",
    "    \n",
    "    return -np.clip(min_n, 10**(-precision), 1), np.clip(max_n, 10**(-precision), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_belief_update_decoupling_charnes_cooper(a, o, nzb_states, rel_suc_states, rel_obs_suc_states, precision):\n",
    "    new_bui = None\n",
    "    new_bdc = []\n",
    "    \n",
    "    if len(rel_obs_suc_states) == 1:\n",
    "        cs = rel_obs_suc_states[0]\n",
    "        new_bui = sparse.csr_matrix(([-1.0,1.0],([cs,cs],[0,1])), shape = (states,2))\n",
    "    else:\n",
    "        nr_nzb_states = len(nzb_states)\n",
    "        \n",
    "        # Belief uncertainty intervals\n",
    "        nr_ros_states = len(rel_obs_suc_states)\n",
    "        cols = np.zeros(2*nr_ros_states, dtype = int)\n",
    "        cols[range(1,2*nr_ros_states, 2)] = 1\n",
    "        rows, data = np.zeros(2*nr_ros_states), np.zeros(2 * nr_ros_states)\n",
    "        for k in range(nr_ros_states): #rel_obs_suc_states\n",
    "            j = rel_obs_suc_states[k]\n",
    "            rows[2*k], rows[2*k+1] = j, j\n",
    "            data[2*k], data[2*k+1] = decoupling_cc_bui(a, o, j, nzb_states, precision)\n",
    "        new_bui = sparse.csr_matrix((data,(rows,cols)), shape = (states,2))\n",
    "\n",
    "        # Belief distribution constraints\n",
    "        mbs_states = []\n",
    "        for i in rel_obs_suc_states:\n",
    "            if rel_suc_states.count(i) > 1:\n",
    "                mbs_states += [i]\n",
    "        for k in range(nr_nzb_states):\n",
    "            i = nzb_states[k]\n",
    "            i_suc_states = sorted(set(relevant_states_list[a][i]) & set(obs_states_list[o][1]))\n",
    "\n",
    "            if len(i_suc_states) > 0:\n",
    "                min_coeffs, max_coeffs = [1] * len(i_suc_states), [-1] * len(i_suc_states)\n",
    "                for l in range(len(i_suc_states)):\n",
    "                    j = i_suc_states[l]\n",
    "                    if j in mbs_states:\n",
    "                        min_coeffs[l], max_coeffs[l] = decoupling_cc_bc(a, o, k, j, nzb_states, precision)\n",
    "\n",
    "                min_const, max_const = decoupling_cc_n(a, o, k, nzb_states, precision)\n",
    "\n",
    "                new_bdc.append((i_suc_states,max_coeffs,min_const))\n",
    "                new_bdc.append((i_suc_states,min_coeffs,max_const))\n",
    "\n",
    "    return (new_bui, new_bdc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main loop (iterate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate(method, spud, factor, nr_trns_samples, problem_name, experiment, precision, minutes):\n",
    "    beliefs = [initial_belief]\n",
    "    rewards = []\n",
    "    transitions = []\n",
    "    times = []\n",
    "\n",
    "    # uncertain belief states counter\n",
    "    ubsc = 0\n",
    "\n",
    "    init_obs =  next(j for j in range(obs) if (next(i for i in range(states) if beliefs[ubsc][0][i,0] != 0 or beliefs[ubsc][0][i,1] != 0)) in obs_states_list[j][1])\n",
    "    b_info = [[0, -1, init_obs]]\n",
    "    t_info = []\n",
    "    r_info = []\n",
    "\n",
    "    while ubsc < len(beliefs):# and ubsc <= 21:\n",
    "        try:\n",
    "            # current observation\n",
    "            co = b_info[ubsc][2]\n",
    "            # non-zero belief states\n",
    "            nzb_states = beliefs[ubsc][0][:,1].nonzero()[0]\n",
    "\n",
    "            update_belief_constraints(beliefs[ubsc], nzb_states)\n",
    "            for a in obs_act_list[co][1]:\n",
    "                rel_suc_states = [j for i in nzb_states for j in relevant_states_list[a][i]]\n",
    "\n",
    "                for o in range(obs):\n",
    "                    rel_obs_suc_states = sorted(set(rel_suc_states) & set(obs_states_list[o][1]))\n",
    "\n",
    "                    if len(rel_obs_suc_states) >= 1:\n",
    "                        new_belief = None\n",
    "                        if method == \"sampling\":\n",
    "                            new_belief = comp_belief_update_sampling(a, o, nzb_states, rel_obs_suc_states, spud, nr_trns_samples, precision, beliefs[ubsc])\n",
    "                        elif method == \"pd_gurobi\":\n",
    "                            new_belief = comp_belief_update_decoupling_gurobi(a, o, nzb_states, rel_suc_states, rel_obs_suc_states, precision)\n",
    "                        else:\n",
    "                            new_belief = comp_belief_update_decoupling_charnes_cooper(a, o, nzb_states, rel_suc_states, rel_obs_suc_states, precision)\n",
    "                        transitions.append(comp_transition(a,o, nzb_states, precision))\n",
    "                        \n",
    "                        beliefs.append(new_belief)\n",
    "                        b_info.append([ubsc, a, o])\n",
    "                        t_info.append([ubsc, a, o, len(beliefs)-1])\n",
    "                    if((time.time() - start_time) > minutes*60):\n",
    "                        break\n",
    "                \n",
    "                rewards.append(comp_reward(a, nzb_states, precision))\n",
    "                r_info.append([ubsc, a])\n",
    "                if((time.time() - start_time) > minutes*60):\n",
    "                    break\n",
    "            ubsc += 1\n",
    "            \n",
    "            iter_time = time.time() - start_time\n",
    "            times.append([problem_name, ubsc, method, spud, iter_time])\n",
    "            if(ubsc % 10 == 0):\n",
    "                print(\"Problem: %s\\t Method: %s\\t States explored: %i\\t Sample spacing: %f\\t Duration = %f seconds\" % (prob,method, ubsc, spud, iter_time))\n",
    "            \n",
    "            if(iter_time > minutes*60):\n",
    "                print(f\"Timeout ({minutes} minutes)\")\n",
    "                break\n",
    "            #else:\n",
    "            #    print(\"Next uncertain belief state\")\n",
    "        except Exception as exc:\n",
    "            print(\"Caught exception:\", exc)\n",
    "            break\n",
    "    \n",
    "    dir_name = \"data%i/%s_%s_%s_f%s/\" % (experiment,problem_name,method,str(spud),str(factor))\n",
    "    os.makedirs(os.path.dirname(dir_name+\"beliefs.txt\"), exist_ok=True)\n",
    "    with open(dir_name+\"beliefs.txt\", \"w\", newline=\"\") as outfile:\n",
    "        for row in beliefs:\n",
    "            bel_rows = row[0][:,0].nonzero()[0]\n",
    "            for br in bel_rows:\n",
    "                outfile.write(f\"{states_list[br]} {round(row[0][br,0], precision)} {round(row[0][br,1],precision)} \")\n",
    "            outfile.write(f\"\\n{len(row[1])}\\n\")\n",
    "            for item in row[1]:\n",
    "                outfile.write(\" \".join(map(str,item))+\"\\n\")\n",
    "            outfile.write(\"\\n\")\n",
    "    \n",
    "    with open(dir_name+\"b_info.txt\", \"w\", newline=\"\") as outfile:\n",
    "        for item in b_info:\n",
    "            outfile.write(\" \".join(map(str,item))+\"\\n\")\n",
    "\n",
    "    with open(dir_name+\"transitions.txt\", \"w\", newline=\"\") as outfile:\n",
    "        for item in transitions:\n",
    "            outfile.write(\" \".join(map(str,item))+\"\\n\")\n",
    "    \n",
    "    with open(dir_name+\"t_info.txt\", \"w\", newline=\"\") as outfile:\n",
    "        for item in t_info:\n",
    "            outfile.write(\" \".join(map(str,item))+\"\\n\")\n",
    "\n",
    "    with open(dir_name+\"rewards.txt\", \"w\", newline=\"\") as outfile:\n",
    "        for item in rewards:\n",
    "            outfile.write(\" \".join(map(str,item))+\"\\n\")\n",
    "    \n",
    "    with open(dir_name+\"r_info.txt\", \"w\", newline=\"\") as outfile:\n",
    "        for item in r_info:\n",
    "            outfile.write(\" \".join(map(str,item))+\"\\n\")\n",
    "    \n",
    "    with open(dir_name+\"times.txt\", \"w\", newline=\"\") as outfile:\n",
    "        for item in times:\n",
    "            outfile.write(\" \".join(map(str,item))+\"\\n\")\n",
    "\n",
    "    return len(beliefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = 3\n",
    "start_time = None\n",
    "problems = [\"cheese_maze_u1\", \"cheese_maze_u2\", \"cheese_maze_u3\", \"cheese_maze_u4\", \"cheese_maze_u5\"]\n",
    "methods = [\"pd_gurobi\", \"pd_cc\", \"sampling\"]\n",
    "spuds = [100, 1000]\n",
    "factor = [2,5]\n",
    "precision = 6\n",
    "minutes = 5\n",
    "\n",
    "for prob in problems:\n",
    "    for method in methods:\n",
    "        if method == \"sampling\":\n",
    "            for spud in spuds:\n",
    "                for fac in factor:\n",
    "                    start_time = time.time()\n",
    "                    if prob == \"aircraft\":\n",
    "                        read_data_sparse(prob)\n",
    "                    else:\n",
    "                        read_data(prob)\n",
    "                    print(\"Read data\")\n",
    "                    update_constants()\n",
    "                    print(\"Updated constants\")\n",
    "                    precomp()\n",
    "                    print(\"Completed precomp\")\n",
    "                    precomp_min_max()\n",
    "                    print(\"Completed min_max\")\n",
    "\n",
    "                    nr_trns_samples = precomp_trns_samples(spud, fac)\n",
    "                    print(\"Completed precomp trns samples\")\n",
    "                    explored = iterate(\"sampling\", spud, fac, nr_trns_samples, prob, experiment, precision, minutes)\n",
    "                    print(\"Finished problem: %s\\t Method: %s\\t States found: %i\\t Sample spacing: %i\" % (prob,\"sampling\", explored, spud))\n",
    "        else:\n",
    "            start_time = time.time()\n",
    "            if prob == \"aircraft\":\n",
    "                read_data_sparse(prob)\n",
    "            else:\n",
    "                read_data(prob)\n",
    "            print(\"Read data\")\n",
    "            update_constants()\n",
    "            print(\"Updated constants\")\n",
    "            precomp()\n",
    "            print(\"Completed precomp\")\n",
    "            precomp_min_max()\n",
    "            print(\"Completed min_max\")\n",
    "\n",
    "            explored = iterate(method, 0, 0, [], prob, experiment, precision, minutes)\n",
    "            print(\"Finished problem: %s\\t Method: %s\\t States found: %i\" % (prob,method, explored))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bfda8af69f832ed9a0394bac79411f43fbde2370a1e6929547e266674831ebb8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
